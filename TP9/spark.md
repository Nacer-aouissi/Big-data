# ğŸ”¥ Spark Requirements and Instructions

## ğŸ“‹ Requirements

- ğŸ˜ Hadoop 3.3.6
- âš¡ Spark 3.5.0
- â˜• Java 8
- ğŸ³ Docker
- ğŸ“¦ Maven
- ğŸ’» VS Code (or any IDE)
- ğŸ§ Linux or similar system

## 1ï¸âƒ£ Testing

### ğŸš€ Launching Hadoop Containers

```bash
docker start hadoop-master hadoop-worker1 hadoop-worker2
docker exec -it hadoop-master bash
./start-hadoop.sh
```

### ğŸ“ Creating Input Folder and Random Text File

```bash
hdfs dfs -mkdir -p input
hdfs dfs -put words.txt input
```

### ğŸ’» Opening Spark Shell

```bash
spark-shell
```

### âš™ï¸ Running Process

```scala
val lines = sc.textFile("file1.txt")
val words = lines.flatMap(_.split("\\s+"))
val wc = words.map(w => (w, 1)).reduceByKey(_ + _)
wc.saveAsTextFile("file1.count")
```

## 2ï¸âƒ£ Operating on Cluster

### ğŸ“ Creating Maven Project

Project structure:

```
wordcount-spark/
â”œâ”€â”€ pom.xml
â””â”€â”€ src/
    â””â”€â”€ main/
        â””â”€â”€ java/
            â””â”€â”€ spark/
                â””â”€â”€ batch/
                    â””â”€â”€ tp21/
                        â””â”€â”€ WordCountTask.java
```

### ğŸ“¤ Building and Uploading to Docker

```bash
docker cp target/wordcount-spark-1.0-SNAPSHOT.jar hadoop-master:/root/wordcount-spark.jar
```

### ğŸš€ Launching the Operation

```bash
spark-submit \
  --class spark.batch.tp9.WordCountTask \
  --master yarn \
  --deploy-mode cluster \
  wordcount-spark.jar input/words.txt out-spark2
```

## 3ï¸âƒ£ Using Spark Streaming

### ğŸ“ Creating Maven Project

Project structure:

```
stream/
â”œâ”€â”€ pom.xml
â””â”€â”€ src/
    â””â”€â”€ main/
        â””â”€â”€ java/
            â””â”€â”€ spark/
                â””â”€â”€ streaming/
                    â””â”€â”€ tp9/
                        â””â”€â”€ Stream.java
```

### ğŸ“¤ Building JAR File and Uploading to Docker

```bash
docker cp target/stream-1.0-SNAPSHOT.jar hadoop-master:/root/wordcount-spark.jar
```

### ğŸ”„ Starting Streaming Process

1. ğŸ”‘ Access Hadoop master bash:

```bash
docker exec -it hadoop-master bash
```

2. ğŸ“¥ Install netcat:

```bash
apt update
apt install netcat
```

3. ğŸ”Œ Start entry port:

```bash
nc -lk 9999
```

4. ğŸš€ Start Spark streaming:

```bash
spark-submit --class spark.streaming.tp9.Stream --master local wordcount-spark.jar > out
```

5. âœï¸ Write some words in entry port and track the process in the 2nd port

6. ğŸ“Š View results:

```bash
cat out
```
